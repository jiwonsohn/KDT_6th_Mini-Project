{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 패혈증(Sepsis) 생존/사망 여부 예측 모델 (사망->1)\n",
    "- .csv\n",
    "- 피쳐: 3개 (환자 나이, 환자 성별, 환자의 패혈증 발병 횟수)\n",
    "- 타겟: 9일 후 사망/생존 여부\n",
    "- 학습: 지도학습 >> 분류 >> 2진 분류\n",
    "- 알고리즘: DNN (MultiLayer Perceptron; 은닉층 min 2개)\n",
    "- 프레임워크: pytorch\n",
    "***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model 모듈 로딩\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import torch.optim as optim\n",
    "from torchmetrics.classification import BinaryF1Score, BinaryAccuracy, BinaryRecall, BinaryPrecision\n",
    "from torchmetrics.classification import BinaryConfusionMatrix\n",
    "from torchinfo import summary\n",
    "import torch.optim.lr_scheduler as lr_scheduler\n",
    "\n",
    "from custom_utils import *\n",
    "\n",
    "# Data 로딩 & 시각화 모듈 로딩\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.preprocessing import *\n",
    "from sklearn.model_selection import train_test_split\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 모듈 버전 확인\n",
    "def ver_check():\n",
    "    print(f'torch v.{torch.__version__}')\n",
    "    print(f'pandas v.{pd.__version__}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch v.2.4.1\n",
      "pandas v.2.0.3\n"
     ]
    }
   ],
   "source": [
    "ver_check()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 랜덤 고정\n",
    "torch.manual_seed(1)\n",
    "\n",
    "# 텐서 저장 및 실행 위치 고정\n",
    "DEVICE = 'cuda' if torch.cuda.is_available() else 'cpu'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 데이터 로드 & 타겟/피쳐 분리"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "        age_years  sex_0male_1female  episode_number  \\\n",
      "129250         33                  1               1   \n",
      "129251         58                  0               1   \n",
      "129252         44                  0               2   \n",
      "129253         61                  0               3   \n",
      "129254         78                  0               1   \n",
      "\n",
      "        hospital_outcome_1alive_0dead  \n",
      "129250                              1  \n",
      "129251                              1  \n",
      "129252                              1  \n",
      "129253                              0  \n",
      "129254                              1  \n",
      "\n",
      "hospital_outcome_1alive_0dead\n",
      "1    117544\n",
      "0     11711\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "### 데이터 로딩\n",
    "DATA_FILE = r'./data/total_sepsis.csv'\n",
    "\n",
    "rawDF = pd.read_csv(DATA_FILE)\n",
    "\n",
    "# 확인\n",
    "print(rawDF.tail(5))\n",
    "print()\n",
    "print(rawDF[rawDF.columns[-1]].value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "hospital_outcome_1alive_0dead\n",
       "0    117544\n",
       "1     11711\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 타겟 변수 변환\n",
    "# dead -> 1, alive -> 0\n",
    "label = {0:1, 1:0}\n",
    "rawDF[rawDF.columns[-1]].replace(label, inplace=True)\n",
    "\n",
    "rawDF[rawDF.columns[-1]].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "featreDF=> (129255, 3) 2D\n",
      "targetDF=> (129255, 1) 2D\n"
     ]
    }
   ],
   "source": [
    "# 타겟 & 피쳐 분리\n",
    "targetDF = rawDF[[rawDF.columns[-1]]]\n",
    "featureDF = rawDF[rawDF.columns[:-1]]\n",
    "\n",
    "# 타겟 & 피쳐 shape 확인\n",
    "print(f\"featreDF=> {featureDF.shape} {featureDF.ndim}D\")\n",
    "print(f\"targetDF=> {targetDF.shape} {targetDF.ndim}D\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 모델 클래스 설계 & 정의\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# [테스트]\n",
    "in_out_ = 5\n",
    "perceptron = [10,50,25,5]\n",
    "model = SepsisLODModel2(5, perceptron)\n",
    "\n",
    "# in_out_ = 5\n",
    "# h_in_ = [10, 50, 25]\n",
    "# h_out_ = [50,25, 10]\n",
    "\n",
    "# model = SepsisLODModel(in_out=in_out_, h_in=h_in_, h_out=h_out_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SepsisLODModel2(\n",
      "  (in_layer): Linear(in_features=3, out_features=10, bias=True)\n",
      "  (hd_layers): ModuleList(\n",
      "    (0): Linear(in_features=10, out_features=50, bias=True)\n",
      "    (1): Linear(in_features=50, out_features=25, bias=True)\n",
      "    (2): Linear(in_features=25, out_features=5, bias=True)\n",
      "  )\n",
      "  (ot_layer): Linear(in_features=5, out_features=1, bias=True)\n",
      ")\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(model)\n",
    "print()\n",
    "# summary(model, input_size=(130000, 3))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 데이터셋 클래스 설계 & 정의\n",
    "<hr>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 3])\n",
      "torch.Size([1, 1])\n",
      "tensor([[21.,  1.,  1.]])\n",
      "tensor([[0.]])\n"
     ]
    }
   ],
   "source": [
    "## [테스트] 데이터셋 인스턴스 생성\n",
    "\n",
    "# 데이터셋 인스턴스 생성\n",
    "SepsisDS = SepsisDataset(featureDF, targetDF)\n",
    "\n",
    "# 데이터로더 인스턴스 생성\n",
    "SepsisDL = DataLoader(SepsisDS)\n",
    "\n",
    "for feature, label in SepsisDL: \n",
    "    print(feature.shape, label.shape, feature, label, sep='\\n')\n",
    "    break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### train, valid 데이터셋 분리"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(featureDF, targetDF,\n",
    "                                                  test_size=0.1,\n",
    "                                                  stratify=targetDF,\n",
    "                                                  random_state=10)\n",
    "\n",
    "X_train, X_val, y_train, y_val = train_test_split(X_train, y_train,\n",
    "                                                  test_size=0.1,\n",
    "                                                  stratify=y_train,\n",
    "                                                  random_state=10)\n",
    "\n",
    "# dataset_print(X_train,y_train,X_test,y_test,X_val,y_val)\n",
    "\n",
    "# 학습용, 검증용 데이터셋\n",
    "trainDS = SepsisDataset(X_train, y_train)\n",
    "valDS = SepsisDataset(X_val, y_val)\n",
    "testDS = SepsisDataset(X_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 학습_준비\n",
    "- 학습_횟수 : EPOCH         <- 처음~끝까지 공부하는 단위\n",
    "- 배치_크기 : BATCH_SIZE    <- 한번에 학습할 데이터셋 양 \n",
    "- 위치_지정 : DEVICE    <- 텐서 저장 및 실행 위치 (GPU/CPU)\n",
    "- 학_습_률 : LR 가중치와 절편 업데이트 시 경사하강법으로 업데이트 간격 설정 0.001~0.1 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "### 학습 진행 관련 설정\n",
    "EPOCH = 100\n",
    "BATCH_SIZE = 1000\n",
    "LR = 0.001"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "' \\nperceptron = [50, 100, 300, 150, 50]\\n[14/15]\\n- [Train] LOSS: 0.27644 Score: 0.96708\\n- [Valid] LOSS: 0.28517 Score: 0.28517\\n'"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "''' \n",
    "perceptron = [50, 100, 300, 150, 50]\n",
    "[14/15]\n",
    "- [Train] LOSS: 0.27644 Score: 0.96708\n",
    "- [Valid] LOSS: 0.28517 Score: 0.28517\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 모델 인스턴스 \n",
    "perceptron = [100,500,250,50]\n",
    "model = SepsisLODModel(in_out=5, perceptrons=perceptron).to(DEVICE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 학습용 데이터로더 인스턴스\n",
    "trainDL = DataLoader(trainDS, batch_size=BATCH_SIZE, drop_last=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 최적화, 손실함수 인스턴스 생성"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[9486, 95210]\n",
      "[0.09060518071368534, 0.9093948192863147]\n",
      "10.036896479021717\n"
     ]
    }
   ],
   "source": [
    "## 가중치 부여\n",
    "numSample_list = [y_train.value_counts().values[1], y_train.value_counts().values[0]]\n",
    "weights = [1-(x / sum(numSample_list)) for x in numSample_list][0]\n",
    "ratio = y_train.value_counts().values[0]/y_train.value_counts().values[1]\n",
    "\n",
    "print(numSample_list)\n",
    "print(weights)\n",
    "print(ratio)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\KDP-43\\anaconda3\\envs\\torch_38\\lib\\site-packages\\torch\\optim\\lr_scheduler.py:60: UserWarning: The verbose parameter is deprecated. Please use get_last_lr() to access the learning rate.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "# 최적화 인스턴스 => W,b 텐서 즉, model.parameters() 전달\n",
    "optimizer=optim.Adam(model.parameters(), lr=LR)\n",
    "\n",
    "# 손실함수 인스턴스 => 분류 => 이진분류 BinaryCrossEntropyLoss =>  BCELoss \n",
    "# 클래스 가중치 부여\n",
    "\n",
    "weightsTS = torch.FloatTensor(weights) \n",
    "crossLoss=nn.BCELoss(weight=weightsTS)\n",
    "# weightsTS = torch.FloatTensor([ratio])\n",
    "# crossLoss = nn.BCEWithLogitsLoss(pos_weight=weightsTS)\n",
    "\n",
    "\n",
    "# 모델 성능함수 인스턴스\n",
    "recall_func = BinaryRecall()\n",
    "f1score_func = BinaryF1Score()\n",
    "\n",
    "precis_func = BinaryPrecision()\n",
    "specfi_func = BinarySpecificity()\n",
    "\n",
    "metric = BinaryConfusionMatrix()\n",
    "\n",
    "# 최적화 스케줄링 인스턴스 생성 => lr 조절 및 성능 개선 여부 체크\n",
    "scheduler = lr_scheduler.ReduceLROnPlateau(optimizer, patience=5, \n",
    "                                           verbose=True, factor=0.9)\n",
    "#\t\t\t\t\t\t\t\t\t\t\t=> patience=10(default)\n",
    "# \t\t\t\t\t\t\t\t\t\t\t=> factor: lr 감소 비율 설정\n",
    "#\t\t\t\t\t\t\t\t\t\t\t=> threshold: s"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 학습"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> 모델 저장 준비"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "# 저장 경로\n",
    "SAVE_PATH = r'./models/Adam/alive_0_noSMOTE_weight_0109_BCE_no_thr/'\n",
    "\n",
    "# 모델 구조 & 파라미터 모두 저장\n",
    "SAVE_MODEL = 'model_all.pth'\n",
    "\n",
    "# 경로상 폴더 존재 여부 체크\n",
    "if not os.path.exists(SAVE_PATH):\n",
    "    os.makedirs(SAVE_PATH)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> 학습 진행"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "104696\n",
      "BATCH_CNT => 104.696\n",
      "104\n"
     ]
    }
   ],
   "source": [
    "## 학습 효과 확인 손실값과 성능평가값 저장 필요\n",
    "\n",
    "LOSS_history  = {'Train':[], 'Val':[] }\n",
    "Recall_history = {'Train':[], 'Val':[] }\n",
    "F1score_history = {'Train':[], 'Val':[] }\n",
    "Precis_history = {'Train':[], 'Val':[] }\n",
    "specfi_history = {'Train':[], 'Val':[] }\n",
    "\n",
    "BATCH_CNT = len(trainDS)/BATCH_SIZE\n",
    "print(len(trainDS))\n",
    "print(f'BATCH_CNT => {BATCH_CNT}')\n",
    "print(len(trainDL))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "ename": "IndexError",
     "evalue": "index 1 is out of bounds for dimension 1 with size 1",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[20], line 19\u001b[0m\n\u001b[0;32m     16\u001b[0m         pre_y \u001b[38;5;241m=\u001b[39m model(featureTS)\n\u001b[0;32m     18\u001b[0m \t\t\u001b[38;5;66;03m# 손실계산\u001b[39;00m\n\u001b[1;32m---> 19\u001b[0m         loss \u001b[38;5;241m=\u001b[39m crossLoss(pre_y, \u001b[43mtargetTS\u001b[49m\u001b[43m[\u001b[49m\u001b[43m:\u001b[49m\u001b[43m,\u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m]\u001b[49m)\n\u001b[0;32m     20\u001b[0m         loss_total \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m loss\u001b[38;5;241m.\u001b[39mitem()\n\u001b[0;32m     22\u001b[0m \t\t\u001b[38;5;66;03m# 성능평가 계산\u001b[39;00m\n",
      "\u001b[1;31mIndexError\u001b[0m: index 1 is out of bounds for dimension 1 with size 1"
     ]
    }
   ],
   "source": [
    "\n",
    "for epoch in range(EPOCH):\n",
    "    \n",
    "\t\n",
    "\t# 학습 모드로 모델 설정\n",
    "    model.train()\n",
    "    \n",
    "    loss_total =0\n",
    "    recall_total =0\n",
    "    f1score_total =0\n",
    "    precis_total =0\n",
    "\n",
    "\t# 배치크기만큼 데이터 로딩 & 학습 진행\n",
    "    for featureTS, targetTS in trainDL:\n",
    "        \n",
    "\t\t# 1 epoch 학습\n",
    "        pre_y = model(featureTS)\n",
    "        \n",
    "\t\t# 손실계산\n",
    "        loss = crossLoss(pre_y, targetTS)\n",
    "        loss_total += loss.item()\n",
    "        \n",
    "\t\t# 성능평가 계산\n",
    "        score_recall = recall_func(pre_y, targetTS)\n",
    "        recall_total += score_recall.item()\n",
    "        \n",
    "        score_f1 = f1score_func(pre_y, targetTS)\n",
    "        f1score_total += score_f1.item()\n",
    "        \n",
    "        score_precis = precis_func(pre_y, targetTS)\n",
    "        precis_total += score_precis.item()\n",
    "        \n",
    "        score_specif = specfi_func(pre_y, targetTS)\n",
    "        specfi_total = score_specif.item()\n",
    "        \n",
    "\t\t# 최적화 진행\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "\t# 한 에포크에 대해 검증\n",
    "    # 모델 -> 검증 모드로 설정\n",
    "    model.eval()\n",
    "    \n",
    "    with torch.no_grad():\t\t\t# required_grade= True 로 설정된 파라미터 해제!!\n",
    "        # 검증 데이터셋\n",
    "        val_featureTS = torch.FloatTensor( valDS.featureDF.values )\n",
    "        val_targetTS = torch.FloatTensor( valDS.targetDF.values )\n",
    "        \n",
    "\t\t# 평가\n",
    "        pre_val = model(val_featureTS)\n",
    "        \n",
    "\t\t# 손실\n",
    "        loss_val = crossLoss(pre_val, val_targetTS)\n",
    "        # 성능평가\n",
    "        recall_val = recall_func(pre_val, val_targetTS)\n",
    "        f1score_val = f1score_func(pre_val, val_targetTS)\n",
    "        precis_val = precis_func(pre_val, val_targetTS)\n",
    "        specfi = specfi_func(pre_val, val_targetTS)\n",
    "        \n",
    "\t# 한 에포크 당 손실값과 성능평가값 저장\n",
    "    LOSS_history['Train'].append(loss_total/BATCH_CNT)\n",
    "    Recall_history['Train'].append(recall_total/BATCH_CNT)\n",
    "    F1score_history['Train'].append(f1score_total/BATCH_CNT)\n",
    "    Precis_history['Train'].append(precis_total/BATCH_CNT)\n",
    "    specfi_history['Train'].append(specfi_total/BATCH_CNT)\n",
    "    \n",
    "    LOSS_history['Val'].append(loss_val)\n",
    "    Recall_history['Val'].append(recall_val)\n",
    "    F1score_history['Val'].append(f1score_val)\n",
    "    Precis_history['Val'].append(precis_val)\n",
    "    specfi_history['Val'].append(score_precis)\n",
    "    \n",
    "    print(f\"[{epoch}/{EPOCH}]\\n- [Train] LOSS: {LOSS_history['Train'][-1]:.5f} \\\n",
    "          Specificity: {specfi_history['Train'][-1]:.5f}\\\n",
    "          Recall: {Recall_history['Train'][-1]:.5f} \\\n",
    "          Precision: {Precis_history['Train'][-1]:.5f} \\\n",
    "          F1score: {F1score_history['Train'][-1]:.5f}\")\n",
    "    \n",
    "    print(f\"- [Valid] LOSS: {LOSS_history['Val'][-1]:.5f} \\\n",
    "          Specificity: {specfi_history['Val'][-1]:.5f}\\\n",
    "          Recall: {Recall_history['Val'][-1]:.5f}\\\n",
    "          Precision: {Precis_history['Val'][-1]:.5f}\\\n",
    "          F1score: {F1score_history['Val'][-1]:.5f}\")\n",
    "    \n",
    "    metric.update(pre_val, val_targetTS)\n",
    "    metric_result = metric.compute()\n",
    "    print(metric_result)\n",
    "    \n",
    "\n",
    "\t# 성능이 좋은 학습 가중치 저장----------------------------------\n",
    "    \n",
    "\t# 저장 파일명\n",
    "    SAVE_FILE = f'model_train_wb_{epoch}_{f1score_val:.5f}.pth'\n",
    "\n",
    "    if len( specfi_history['Val']) == 1:\n",
    "        # 첫번째 저장값이라 무조건 모델 저장\n",
    "        torch.save(model.state_dict(), SAVE_PATH+SAVE_FILE)\n",
    "        # 모델 전체 저장\n",
    "        torch.save(model, SAVE_PATH+SAVE_MODEL)\n",
    "    \n",
    "    else:\n",
    "        # 지금 점수[-1]가 이전 최고성능 점수보다 높으면 저장\n",
    "    \tif specfi_history['Val'][-1] > max( specfi_history['Val'][:-1]):\n",
    "            torch.save(model.state_dict(), SAVE_PATH+SAVE_FILE)\n",
    "            torch.save(model, SAVE_PATH+SAVE_MODEL)\n",
    "            \n",
    "\t\t\t\n",
    "\t# 최적화 스케쥴러 인스턴스 업데이트\n",
    "    scheduler.step(loss_val)\n",
    "    # print(f'scheduler.num_bad_epochs =>  {scheduler.num_bad_epochs}', end='  ')\n",
    "    # print(f'scheduler.patience =>  {scheduler.patience}')\n",
    "    \n",
    "\t# 손실 감소(or 성능 개선)이 안될 시, 조기 종료\n",
    "    if scheduler.num_bad_epochs >= scheduler.patience:\n",
    "        print(f'{scheduler.patience} EPOCH 성능 개선이 없어서 조기종료함.')\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "showLossScore2(LOSS_history,Recall_history,F1score_history, specfi_history)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### test 데이터셋 모델 테스트"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 모델 테스트 모드 설정\n",
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    # 검증 데이터셋\n",
    "    test_featrueTS=torch.FloatTensor(testDS.featureDF.values).to(DEVICE)\n",
    "    test_targetTS=torch.FloatTensor(testDS.targetDF.values).to(DEVICE)\n",
    "    \n",
    "    \n",
    "    # 추론/평가\n",
    "    pre_test=model(test_featrueTS)\n",
    "\n",
    "    # 손실\n",
    "    loss_test=crossLoss(pre_test, test_targetTS)\n",
    "    # 성능평가\n",
    "    #score_val=F1Score(task='binary')(pre_test, val_targetTS)\n",
    "    # 성능평가\n",
    "    f1score_test=f1score_func(pre_test, test_targetTS)\n",
    "    recall_test = recall_func(pre_test, test_targetTS)\n",
    "    specif_test = specfi_func(pre_test, test_targetTS)\n",
    "    precis_test = precis_func(pre_test, test_targetTS)\n",
    "    \n",
    "print(f'- [TEST] LOSS : {loss_test.item()} \\\n",
    "      f1-SCORE : {f1score_test.item()}\\\n",
    "      recall: {recall_test.item()}\\\n",
    "      precision: {precis_test.item()}\\\n",
    "      specificity: {specif_test.item()} ' )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "torch_38",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
