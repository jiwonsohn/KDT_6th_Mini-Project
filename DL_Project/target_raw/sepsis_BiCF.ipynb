{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 패혈증(Sepsis) 생존/사망 여부 예측 모델\n",
    "- .csv\n",
    "- 피쳐: 3개 (환자 나이, 환자 성별, 환자의 패혈증 발병 횟수)\n",
    "- 타겟: 9일 후 사망/생존 여부\n",
    "- 학습: 지도학습 >> 분류 >> 2진 분류\n",
    "- 알고리즘: DNN (MultiLayer Perceptron; 은닉층 min 2개)\n",
    "- 프레임워크: pytorch\n",
    "***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model 모듈 로딩\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import torch.optim as optim\n",
    "from torchmetrics.classification import BinaryF1Score, BinaryAccuracy, BinaryRecall, BinaryPrecision\n",
    "from torchmetrics.classification import BinaryConfusionMatrix\n",
    "from torchinfo import summary\n",
    "import torch.optim.lr_scheduler as lr_scheduler\n",
    "\n",
    "from custom_utils import *\n",
    "\n",
    "# Data 로딩 & 시각화 모듈 로딩\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.preprocessing import *\n",
    "from sklearn.model_selection import train_test_split\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 모듈 버전 확인\n",
    "def ver_check():\n",
    "    print(f'torch v.{torch.__version__}')\n",
    "    print(f'pandas v.{pd.__version__}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch v.2.4.1\n",
      "pandas v.2.0.3\n"
     ]
    }
   ],
   "source": [
    "ver_check()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 랜덤 고정\n",
    "torch.manual_seed(1)\n",
    "\n",
    "# 텐서 저장 및 실행 위치 고정\n",
    "DEVICE = 'cuda' if torch.cuda.is_available() else 'cpu'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 데이터 로드 & 타겟/피쳐 분리"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age_years</th>\n",
       "      <th>sex_0male_1female</th>\n",
       "      <th>episode_number</th>\n",
       "      <th>hospital_outcome_1alive_0dead</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>129245</th>\n",
       "      <td>69</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>129246</th>\n",
       "      <td>29</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>129247</th>\n",
       "      <td>79</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>129248</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>129249</th>\n",
       "      <td>77</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>129250</th>\n",
       "      <td>33</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>129251</th>\n",
       "      <td>58</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>129252</th>\n",
       "      <td>44</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>129253</th>\n",
       "      <td>61</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>129254</th>\n",
       "      <td>78</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        age_years  sex_0male_1female  episode_number  \\\n",
       "129245         69                  1               2   \n",
       "129246         29                  0               1   \n",
       "129247         79                  0               1   \n",
       "129248          1                  0               1   \n",
       "129249         77                  0               1   \n",
       "129250         33                  1               1   \n",
       "129251         58                  0               1   \n",
       "129252         44                  0               2   \n",
       "129253         61                  0               3   \n",
       "129254         78                  0               1   \n",
       "\n",
       "        hospital_outcome_1alive_0dead  \n",
       "129245                              1  \n",
       "129246                              1  \n",
       "129247                              1  \n",
       "129248                              1  \n",
       "129249                              0  \n",
       "129250                              1  \n",
       "129251                              1  \n",
       "129252                              1  \n",
       "129253                              0  \n",
       "129254                              1  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "### 데이터 로딩\n",
    "DATA_FILE = r'./data/total_sepsis.csv'\n",
    "\n",
    "rawDF = pd.read_csv(DATA_FILE)\n",
    "\n",
    "# 확인\n",
    "rawDF.tail(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "featreDF=> (129255, 3) 2D\n",
      "targetDF=> (129255, 1) 2D\n"
     ]
    }
   ],
   "source": [
    "# 타겟 & 피쳐 분리\n",
    "targetDF = rawDF[[rawDF.columns[-1]]]\n",
    "featureDF = rawDF[rawDF.columns[:-1]]\n",
    "\n",
    "# 타겟 & 피쳐 shape 확인\n",
    "print(f\"featreDF=> {featureDF.shape} {featureDF.ndim}D\")\n",
    "print(f\"targetDF=> {targetDF.shape} {targetDF.ndim}D\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 모델 클래스 설계 & 정의\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# [테스트]\n",
    "in_out_ = 5\n",
    "perceptron = [10,50,25,5]\n",
    "model = SepsisLODModel(5, perceptron)\n",
    "\n",
    "# in_out_ = 5\n",
    "# h_in_ = [10, 50, 25]\n",
    "# h_out_ = [50,25, 10]\n",
    "\n",
    "# model = SepsisLODModel(in_out=in_out_, h_in=h_in_, h_out=h_out_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SepsisLODModel(\n",
      "  (in_layer): Linear(in_features=3, out_features=10, bias=True)\n",
      "  (hd_layers): ModuleList(\n",
      "    (0): Linear(in_features=10, out_features=50, bias=True)\n",
      "    (1): Linear(in_features=50, out_features=25, bias=True)\n",
      "    (2): Linear(in_features=25, out_features=5, bias=True)\n",
      "  )\n",
      "  (ot_layer): Linear(in_features=5, out_features=1, bias=True)\n",
      ")\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(model)\n",
    "print()\n",
    "# summary(model, input_size=(130000, 3))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 데이터셋 클래스 설계 & 정의\n",
    "<hr>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 3])\n",
      "torch.Size([1, 1])\n",
      "tensor([[21.,  1.,  1.]])\n",
      "tensor([[1.]])\n"
     ]
    }
   ],
   "source": [
    "## [테스트] 데이터셋 인스턴스 생성\n",
    "\n",
    "# 데이터셋 인스턴스 생성\n",
    "SepsisDS = SepsisDataset(featureDF, targetDF)\n",
    "\n",
    "# 데이터로더 인스턴스 생성\n",
    "SepsisDL = DataLoader(SepsisDS)\n",
    "\n",
    "for feature, label in SepsisDL: \n",
    "    print(feature.shape, label.shape, feature, label, sep='\\n')\n",
    "    break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### train, valid 데이터셋 분리"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train: (104696, 3) 2D\n",
      "y_train: (104696, 1) 2D\n",
      "y_train :\n",
      " hospital_outcome_1alive_0dead\n",
      "1                                95210\n",
      "0                                 9486\n",
      "Name: count, dtype: int64\n",
      "y_train :\n",
      " hospital_outcome_1alive_0dead\n",
      "1                                90.939482\n",
      "0                                 9.060518\n",
      "Name: count, dtype: float64\n",
      "\n",
      "X_val: (11633, 3) 2D\n",
      "y_val: (11633, 1) 2D\n",
      "y_val :\n",
      " hospital_outcome_1alive_0dead\n",
      "1                                10579\n",
      "0                                 1054\n",
      "Name: count, dtype: int64\n",
      "y_val :\n",
      " hospital_outcome_1alive_0dead\n",
      "1                                90.939568\n",
      "0                                 9.060432\n",
      "Name: count, dtype: float64\n",
      "\n",
      "X_test: (12926, 3) 2D\n",
      "y_test: (12926, 1) 2D\n",
      "y_test :\n",
      " hospital_outcome_1alive_0dead\n",
      "1                                11755\n",
      "0                                 1171\n",
      "Name: count, dtype: int64\n",
      "y_test :\n",
      " hospital_outcome_1alive_0dead\n",
      "1                                90.94074\n",
      "0                                 9.05926\n",
      "Name: count, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(featureDF, targetDF,\n",
    "                                                  test_size=0.1,\n",
    "                                                  stratify=targetDF,\n",
    "                                                  random_state=10)\n",
    "\n",
    "X_train, X_val, y_train, y_val = train_test_split(X_train, y_train,\n",
    "                                                  test_size=0.1,\n",
    "                                                  stratify=y_train,\n",
    "                                                  random_state=10)\n",
    "\n",
    "dataset_print(X_train,y_train,X_test,y_test,X_val,y_val)\n",
    "\n",
    "# 학습용, 검증용 데이터셋\n",
    "trainDS = SepsisDataset(X_train, y_train)\n",
    "valDS = SepsisDataset(X_val, y_val)\n",
    "testDS = SepsisDataset(X_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 학습_준비\n",
    "- 학습_횟수 : EPOCH         <- 처음~끝까지 공부하는 단위\n",
    "- 배치_크기 : BATCH_SIZE    <- 한번에 학습할 데이터셋 양 \n",
    "- 위치_지정 : DEVICE    <- 텐서 저장 및 실행 위치 (GPU/CPU)\n",
    "- 학_습_률 : LR 가중치와 절편 업데이트 시 경사하강법으로 업데이트 간격 설정 0.001~0.1 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "### 학습 진행 관련 설정\n",
    "EPOCH = 100\n",
    "BATCH_SIZE = 1000\n",
    "LR = 0.001"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "' \\nperceptron = [50, 100, 300, 150, 50]\\n[14/15]\\n- [Train] LOSS: 0.27644 Score: 0.96708\\n- [Valid] LOSS: 0.28517 Score: 0.28517\\n'"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "''' \n",
    "perceptron = [50, 100, 300, 150, 50]\n",
    "[14/15]\n",
    "- [Train] LOSS: 0.27644 Score: 0.96708\n",
    "- [Valid] LOSS: 0.28517 Score: 0.28517\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 모델 인스턴스 \n",
    "perceptron = [100,500,250,50]\n",
    "model = SepsisLODModel(in_out=5, perceptrons=perceptron).to(DEVICE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 학습용 데이터로더 인스턴스\n",
    "trainDL = DataLoader(trainDS, batch_size=BATCH_SIZE, drop_last=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 최적화, 손실함수 인스턴스 생성"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\KDP-43\\anaconda3\\envs\\torch_38\\lib\\site-packages\\torch\\optim\\lr_scheduler.py:60: UserWarning: The verbose parameter is deprecated. Please use get_last_lr() to access the learning rate.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "# 최적화 인스턴스 => W,b 텐서 즉, model.parameters() 전달\n",
    "optimizer=optim.Adam(model.parameters(), lr=LR)\n",
    "\n",
    "# 손실함수 인스턴스 => 분류 => 이진분류 BinaryCrossEntropyLoss =>  BCELoss \n",
    "#                            예측값은 확률값으로 전달 ==> sigmoid() AF 처리 후 전달\n",
    "crossLoss=nn.BCELoss()\n",
    "\n",
    "# 모델 성능함수 인스턴스\n",
    "recall_func = BinaryRecall(threshold=0.25)\n",
    "f1score_func = BinaryF1Score(threshold=0.25)\n",
    "\n",
    "precis_func = BinaryPrecision(threshold=0.25)\n",
    "specfi_func = BinarySpecificity(threshold=0.25)\n",
    "\n",
    "metric = BinaryConfusionMatrix(threshold=0.25)\n",
    "\n",
    "# 최적화 스케줄링 인스턴스 생성 => lr 조절 및 성능 개선 여부 체크\n",
    "scheduler = lr_scheduler.ReduceLROnPlateau(optimizer, patience=6, \n",
    "                                           verbose=True, factor=0.9)\n",
    "#\t\t\t\t\t\t\t\t\t\t\t=> patience=10(default)\n",
    "# \t\t\t\t\t\t\t\t\t\t\t=> factor: lr 감소 비율 설정\n",
    "#\t\t\t\t\t\t\t\t\t\t\t=> threshold: s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 최적화 인스턴스 \n",
    "optimizer=optim.Adam(model.parameters(), lr=LR)\n",
    "# 손실함수 인스턴스 => 분류 => 이진분류 \n",
    "crossLoss=nn.BCELoss()\n",
    "# 모델 성능함수 인스턴스\n",
    "recall_func = BinaryRecall()\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 학습"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> 모델 저장 준비"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "# 저장 경로\n",
    "SAVE_PATH = r'./models/Adam/alive_1_thr_025/'\n",
    "\n",
    "# 모델 구조 & 파라미터 모두 저장\n",
    "SAVE_MODEL = 'model_all.pth'\n",
    "\n",
    "# 경로상 폴더 존재 여부 체크\n",
    "if not os.path.exists(SAVE_PATH):\n",
    "    os.makedirs(SAVE_PATH)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> 학습 진행"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "104696\n",
      "BATCH_CNT => 104.696\n",
      "104\n"
     ]
    }
   ],
   "source": [
    "## 학습 효과 확인 손실값과 성능평가값 저장 필요\n",
    "\n",
    "LOSS_history  = {'Train':[], 'Val':[] }\n",
    "Recall_history = {'Train':[], 'Val':[] }\n",
    "F1score_history = {'Train':[], 'Val':[] }\n",
    "Precis_history = {'Train':[], 'Val':[] }\n",
    "specfi_history = {'Train':[], 'Val':[] }\n",
    "\n",
    "BATCH_CNT = len(trainDS)/BATCH_SIZE\n",
    "print(len(trainDS))\n",
    "print(f'BATCH_CNT => {BATCH_CNT}')\n",
    "print(len(trainDL))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0/100]\n",
      "- [Train] LOSS: 0.34881           Recall: 0.99335           Precision: 0.90332           Specificity: 0.00000          F1score: 0.94618\n",
      "- [Valid] LOSS: 0.31147           Recall: 1.00000          Precision: 0.90940          Specificity: 0.90600          F1score: 0.95255\n",
      "tensor([[    0,  1054],\n",
      "        [    0, 10579]])\n",
      "[1/100]\n",
      "- [Train] LOSS: 0.30687           Recall: 0.99335           Precision: 0.90332           Specificity: 0.00000          F1score: 0.94618\n",
      "- [Valid] LOSS: 0.29711           Recall: 1.00000          Precision: 0.90940          Specificity: 0.90600          F1score: 0.95255\n",
      "tensor([[    0,  2108],\n",
      "        [    0, 21158]])\n",
      "[2/100]\n",
      "- [Train] LOSS: 0.29556           Recall: 0.99335           Precision: 0.90332           Specificity: 0.00000          F1score: 0.94618\n",
      "- [Valid] LOSS: 0.29932           Recall: 1.00000          Precision: 0.90940          Specificity: 0.90600          F1score: 0.95255\n",
      "tensor([[    0,  3162],\n",
      "        [    0, 31737]])\n",
      "[3/100]\n",
      "- [Train] LOSS: 0.29172           Recall: 0.99335           Precision: 0.90332           Specificity: 0.00000          F1score: 0.94618\n",
      "- [Valid] LOSS: 0.29844           Recall: 1.00000          Precision: 0.90940          Specificity: 0.90600          F1score: 0.95255\n",
      "tensor([[    0,  4216],\n",
      "        [    0, 42316]])\n",
      "[4/100]\n",
      "- [Train] LOSS: 0.29331           Recall: 0.99335           Precision: 0.90332           Specificity: 0.00000          F1score: 0.94618\n",
      "- [Valid] LOSS: 0.28624           Recall: 1.00000          Precision: 0.90940          Specificity: 0.90600          F1score: 0.95255\n",
      "tensor([[    0,  5270],\n",
      "        [    0, 52895]])\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[18], line 13\u001b[0m\n\u001b[0;32m     10\u001b[0m     precis_total \u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m\n\u001b[0;32m     12\u001b[0m \t\u001b[38;5;66;03m# 배치크기만큼 데이터 로딩 & 학습 진행\u001b[39;00m\n\u001b[1;32m---> 13\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m featureTS, targetTS \u001b[38;5;129;01min\u001b[39;00m trainDL:\n\u001b[0;32m     14\u001b[0m         \n\u001b[0;32m     15\u001b[0m \t\t\u001b[38;5;66;03m# 1 epoch 학습\u001b[39;00m\n\u001b[0;32m     16\u001b[0m         pre_y \u001b[38;5;241m=\u001b[39m model(featureTS)\n\u001b[0;32m     18\u001b[0m \t\t\u001b[38;5;66;03m# 손실계산\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\KDP-43\\anaconda3\\envs\\torch_38\\lib\\site-packages\\torch\\utils\\data\\dataloader.py:630\u001b[0m, in \u001b[0;36m_BaseDataLoaderIter.__next__\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    627\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_sampler_iter \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    628\u001b[0m     \u001b[38;5;66;03m# TODO(https://github.com/pytorch/pytorch/issues/76750)\u001b[39;00m\n\u001b[0;32m    629\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_reset()  \u001b[38;5;66;03m# type: ignore[call-arg]\u001b[39;00m\n\u001b[1;32m--> 630\u001b[0m data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_next_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    631\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_yielded \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[0;32m    632\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_dataset_kind \u001b[38;5;241m==\u001b[39m _DatasetKind\u001b[38;5;241m.\u001b[39mIterable \u001b[38;5;129;01mand\u001b[39;00m \\\n\u001b[0;32m    633\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_IterableDataset_len_called \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m \\\n\u001b[0;32m    634\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_yielded \u001b[38;5;241m>\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_IterableDataset_len_called:\n",
      "File \u001b[1;32mc:\\Users\\KDP-43\\anaconda3\\envs\\torch_38\\lib\\site-packages\\torch\\utils\\data\\dataloader.py:673\u001b[0m, in \u001b[0;36m_SingleProcessDataLoaderIter._next_data\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    671\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_next_data\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[0;32m    672\u001b[0m     index \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_next_index()  \u001b[38;5;66;03m# may raise StopIteration\u001b[39;00m\n\u001b[1;32m--> 673\u001b[0m     data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_dataset_fetcher\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfetch\u001b[49m\u001b[43m(\u001b[49m\u001b[43mindex\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# may raise StopIteration\u001b[39;00m\n\u001b[0;32m    674\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_pin_memory:\n\u001b[0;32m    675\u001b[0m         data \u001b[38;5;241m=\u001b[39m _utils\u001b[38;5;241m.\u001b[39mpin_memory\u001b[38;5;241m.\u001b[39mpin_memory(data, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_pin_memory_device)\n",
      "File \u001b[1;32mc:\\Users\\KDP-43\\anaconda3\\envs\\torch_38\\lib\\site-packages\\torch\\utils\\data\\_utils\\fetch.py:52\u001b[0m, in \u001b[0;36m_MapDatasetFetcher.fetch\u001b[1;34m(self, possibly_batched_index)\u001b[0m\n\u001b[0;32m     50\u001b[0m         data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset\u001b[38;5;241m.\u001b[39m__getitems__(possibly_batched_index)\n\u001b[0;32m     51\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m---> 52\u001b[0m         data \u001b[38;5;241m=\u001b[39m [\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset[idx] \u001b[38;5;28;01mfor\u001b[39;00m idx \u001b[38;5;129;01min\u001b[39;00m possibly_batched_index]\n\u001b[0;32m     53\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m     54\u001b[0m     data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset[possibly_batched_index]\n",
      "File \u001b[1;32mc:\\Users\\KDP-43\\anaconda3\\envs\\torch_38\\lib\\site-packages\\torch\\utils\\data\\_utils\\fetch.py:52\u001b[0m, in \u001b[0;36m<listcomp>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m     50\u001b[0m         data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset\u001b[38;5;241m.\u001b[39m__getitems__(possibly_batched_index)\n\u001b[0;32m     51\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m---> 52\u001b[0m         data \u001b[38;5;241m=\u001b[39m [\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdataset\u001b[49m\u001b[43m[\u001b[49m\u001b[43midx\u001b[49m\u001b[43m]\u001b[49m \u001b[38;5;28;01mfor\u001b[39;00m idx \u001b[38;5;129;01min\u001b[39;00m possibly_batched_index]\n\u001b[0;32m     53\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m     54\u001b[0m     data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset[possibly_batched_index]\n",
      "File \u001b[1;32mc:\\Users\\KDP-43\\Desktop\\DL_project\\custom_utils.py:167\u001b[0m, in \u001b[0;36mSepsisDataset.__getitem__\u001b[1;34m(self, idx)\u001b[0m\n\u001b[0;32m    164\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__getitem__\u001b[39m(\u001b[38;5;28mself\u001b[39m, idx):\n\u001b[0;32m    165\u001b[0m \t\u001b[38;5;66;03m# 텐서화\u001b[39;00m\n\u001b[0;32m    166\u001b[0m \tfeatureTS \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mFloatTensor(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfeatureDF\u001b[38;5;241m.\u001b[39miloc[idx]\u001b[38;5;241m.\u001b[39mvalues)\n\u001b[1;32m--> 167\u001b[0m \ttargetTS \u001b[38;5;241m=\u001b[39m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mFloatTensor\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtargetDF\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43miloc\u001b[49m\u001b[43m[\u001b[49m\u001b[43midx\u001b[49m\u001b[43m]\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mvalues\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    169\u001b[0m \t\u001b[38;5;28;01mreturn\u001b[39;00m featureTS, targetTS\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "\n",
    "for epoch in range(EPOCH):\n",
    "    \n",
    "\t\n",
    "\t# 학습 모드로 모델 설정\n",
    "    model.train()\n",
    "    \n",
    "    loss_total =0\n",
    "    recall_total =0\n",
    "    f1score_total =0\n",
    "    precis_total =0\n",
    "\n",
    "\t# 배치크기만큼 데이터 로딩 & 학습 진행\n",
    "    for featureTS, targetTS in trainDL:\n",
    "        \n",
    "\t\t# 1 epoch 학습\n",
    "        pre_y = model(featureTS)\n",
    "        \n",
    "\t\t# 손실계산\n",
    "        loss = crossLoss(pre_y, targetTS)\n",
    "        loss_total += loss.item()\n",
    "        \n",
    "\t\t# 성능평가 계산\n",
    "        score_recall = recall_func(pre_y, targetTS)\n",
    "        recall_total += score_recall.item()\n",
    "        \n",
    "        score_f1 = f1score_func(pre_y, targetTS)\n",
    "        f1score_total += score_f1.item()\n",
    "        \n",
    "        score_precis = precis_func(pre_y, targetTS)\n",
    "        precis_total += score_precis.item()\n",
    "        \n",
    "        score_specif = specfi_func(pre_y, targetTS)\n",
    "        specfi_total = score_specif.item()\n",
    "        \n",
    "\t\t# 최적화 진행\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "\t# 한 에포크에 대해 검증\n",
    "    # 모델 -> 검증 모드로 설정\n",
    "    model.eval()\n",
    "    \n",
    "    with torch.no_grad():\t\t\t# required_grade= True 로 설정된 파라미터 해제!!\n",
    "        # 검증 데이터셋\n",
    "        val_featureTS = torch.FloatTensor( valDS.featureDF.values )\n",
    "        val_targetTS = torch.FloatTensor( valDS.targetDF.values )\n",
    "        \n",
    "\t\t# 평가\n",
    "        pre_val = model(val_featureTS)\n",
    "        \n",
    "\t\t# 손실\n",
    "        loss_val = crossLoss(pre_val, val_targetTS)\n",
    "        # 성능평가\n",
    "        recall_val = recall_func(pre_val, val_targetTS)\n",
    "        f1score_val = f1score_func(pre_val, val_targetTS)\n",
    "        precis_val = precis_func(pre_val, val_targetTS)\n",
    "        specfi = specfi_func(pre_val, val_targetTS)\n",
    "        \n",
    "\t# 한 에포크 당 손실값과 성능평가값 저장\n",
    "    LOSS_history['Train'].append(loss_total/BATCH_CNT)\n",
    "    Recall_history['Train'].append(recall_total/BATCH_CNT)\n",
    "    F1score_history['Train'].append(f1score_total/BATCH_CNT)\n",
    "    Precis_history['Train'].append(precis_total/BATCH_CNT)\n",
    "    specfi_history['Train'].append(specfi_total/BATCH_CNT)\n",
    "    \n",
    "    LOSS_history['Val'].append(loss_val)\n",
    "    Recall_history['Val'].append(recall_val)\n",
    "    F1score_history['Val'].append(f1score_val)\n",
    "    Precis_history['Val'].append(precis_val)\n",
    "    specfi_history['Val'].append(score_precis)\n",
    "    \n",
    "    print(f\"[{epoch}/{EPOCH}]\\n- [Train] LOSS: {LOSS_history['Train'][-1]:.5f} \\\n",
    "          Recall: {Recall_history['Train'][-1]:.5f} \\\n",
    "          Precision: {Precis_history['Train'][-1]:.5f} \\\n",
    "          Specificity: {specfi_history['Train'][-1]:.5f}\\\n",
    "          F1score: {F1score_history['Train'][-1]:.5f}\")\n",
    "    \n",
    "    print(f\"- [Valid] LOSS: {LOSS_history['Val'][-1]:.5f} \\\n",
    "          Recall: {Recall_history['Val'][-1]:.5f}\\\n",
    "          Precision: {Precis_history['Val'][-1]:.5f}\\\n",
    "          Specificity: {specfi_history['Val'][-1]:.5f}\\\n",
    "          F1score: {F1score_history['Val'][-1]:.5f}\")\n",
    "    \n",
    "    metric.update(pre_val, val_targetTS)\n",
    "    metric_result = metric.compute()\n",
    "    print(metric_result)\n",
    "    \n",
    "\n",
    "\t# 성능이 좋은 학습 가중치 저장----------------------------------\n",
    "    \n",
    "\t# 저장 파일명\n",
    "    SAVE_FILE = f'model_train_wb_{epoch}_{f1score_val:.5f}.pth'\n",
    "\n",
    "    if len( F1score_history['Val']) == 1:\n",
    "        # 첫번째 저장값이라 무조건 모델 저장\n",
    "        torch.save(model.state_dict(), SAVE_PATH+SAVE_FILE)\n",
    "        # 모델 전체 저장\n",
    "        torch.save(model, SAVE_PATH+SAVE_MODEL)\n",
    "    \n",
    "    else:\n",
    "        # 지금 점수[-1]가 이전 최고성능 점수보다 높으면 저장\n",
    "    \tif F1score_history['Val'][-1] > max( F1score_history['Val'][:-1]):\n",
    "            torch.save(model.state_dict(), SAVE_PATH+SAVE_FILE)\n",
    "            torch.save(model, SAVE_PATH+SAVE_MODEL)\n",
    "            \n",
    "\t\t\t\n",
    "\t# 최적화 스케쥴러 인스턴스 업데이트\n",
    "    scheduler.step(loss_val)\n",
    "    # print(f'scheduler.num_bad_epochs =>  {scheduler.num_bad_epochs}', end='  ')\n",
    "    # print(f'scheduler.patience =>  {scheduler.patience}')\n",
    "    \n",
    "\t# 손실 감소(or 성능 개선)이 안될 시, 조기 종료\n",
    "    if scheduler.num_bad_epochs >= scheduler.patience:\n",
    "        print(f'{scheduler.patience} EPOCH 성능 개선이 없어서 조기종료함.')\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "showLossScore(LOSS_history,Recall_history,F1score_history)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "showLossScore2(LOSS_history,Recall_history,F1score_history, specfi_history)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### test 데이터셋 모델 테스트"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 모델 테스트 모드 설정\n",
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    # 검증 데이터셋\n",
    "    test_featrueTS=torch.FloatTensor(testDS.featureDF.values).to(DEVICE)\n",
    "    test_targetTS=torch.FloatTensor(testDS.targetDF.values).to(DEVICE)\n",
    "    \n",
    "    \n",
    "    # 추론/평가\n",
    "    pre_test=model(test_featrueTS)\n",
    "\n",
    "    # 손실\n",
    "    loss_test=crossLoss(pre_test, test_targetTS)\n",
    "    # 성능평가\n",
    "    #score_val=F1Score(task='binary')(pre_test, val_targetTS)\n",
    "    # 성능평가\n",
    "    f1score_test=f1score_func(pre_test, test_targetTS)\n",
    "    recall_test = recall_func(pre_test, test_targetTS)\n",
    "    specif_test = specfi_func(pre_test, test_targetTS)\n",
    "    \n",
    "print(f'- [TEST] LOSS : {loss_test.item()} \\\n",
    "      f1-SCORE : {f1score_test.item()}\\\n",
    "      recall: {recall_test.item()}\\\n",
    "      specificity: {specif_test.item()} ' )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 결과: 과대적합\n",
    "<hr>\n",
    "- 해결방안\n",
    "\t* 데이터 재샘플링: 오버샘플링, 언더샘플링\n",
    "\t\t* 오버샘플링: https://mkjjo.github.io/python/2019/01/04/smote_duplicate.html \n",
    "\t* 클래스 가중치 조정: class_weight 파라미터 조정"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "torch_38",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
